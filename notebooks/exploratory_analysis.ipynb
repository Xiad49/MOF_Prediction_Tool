{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "156d8b46",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "{\n",
    "  \"cells\": [\n",
    "    {\n",
    "      \"cell_type\": \"markdown\",\n",
    "      \"metadata\": {},\n",
    "      \"source\": [\n",
    "        \"# Exploratory Analysis (Support Notebook for C++ MOF Pipeline)\\n\",\n",
    "        \"\\n\",\n",
    "        \"> **Scope guard (important):** This notebook is **not** the main pipeline.  \\n\",\n",
    "        \"> Use it only for:\\n\",\n",
    "        \"> - data inspection\\n\",\n",
    "        \"> - plotting\\n\",\n",
    "        \"> - quick experiments\\n\",\n",
    "        \"> - validating outputs produced by the **C++ pipeline**\\n\",\n",
    "        \"\\n\",\n",
    "        \"The production workflow remains:\\n\",\n",
    "        \"\\n\",\n",
    "        \"`preprocessing -> feature engineering -> modeling -> evaluation -> reports` (implemented in C++).\\n\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"markdown\",\n",
    "      \"metadata\": {},\n",
    "      \"source\": [\n",
    "        \"## 1) Configuration\\n\",\n",
    "        \"\\n\",\n",
    "        \"Set paths to your raw data and C++ output folders.  \\n\",\n",
    "        \"This notebook is intentionally lightweight and non-destructive.\\n\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"code\",\n",
    "      \"execution_count\": null,\n",
    "      \"metadata\": {},\n",
    "      \"outputs\": [],\n",
    "      \"source\": [\n",
    "        \"from pathlib import Path\\n\",\n",
    "        \"import re\\n\",\n",
    "        \"import math\\n\",\n",
    "        \"import json\\n\",\n",
    "        \"import warnings\\n\",\n",
    "        \"\\n\",\n",
    "        \"import numpy as np\\n\",\n",
    "        \"import pandas as pd\\n\",\n",
    "        \"import matplotlib.pyplot as plt\\n\",\n",
    "        \"from IPython.display import display\\n\",\n",
    "        \"\\n\",\n",
    "        \"# ----------------------------\\n\",\n",
    "        \"# User-adjustable paths\\n\",\n",
    "        \"# ----------------------------\\n\",\n",
    "        \"PROJECT_ROOT = Path(\\\"..\\\").resolve()   # notebook lives in notebooks/\\n\",\n",
    "        \"RAW_DATA_CSV = PROJECT_ROOT / \\\"data\\\" / \\\"raw\\\" / \\\"mof_descriptors.csv\\\"\\n\",\n",
    "        \"\\n\",\n",
    "        \"# Matches the src/main.cpp output layout from the C++ pipeline\\n\",\n",
    "        \"CPP_OUTPUT_ROOT = PROJECT_ROOT / \\\"output\\\"\\n\",\n",
    "        \"CPP_PROCESSED_CSV = CPP_OUTPUT_ROOT / \\\"data\\\" / \\\"processed\\\" / \\\"cleaned.csv\\\"\\n\",\n",
    "        \"CPP_FEATURES_ALL_CSV = CPP_OUTPUT_ROOT / \\\"data\\\" / \\\"features\\\" / \\\"engineered_all_unscaled.csv\\\"\\n\",\n",
    "        \"CPP_TRAIN_SCALED_CSV = CPP_OUTPUT_ROOT / \\\"data\\\" / \\\"features\\\" / \\\"train_scaled.csv\\\"\\n\",\n",
    "        \"CPP_TEST_SCALED_CSV = CPP_OUTPUT_ROOT / \\\"data\\\" / \\\"features\\\" / \\\"test_scaled.csv\\\"\\n\",\n",
    "        \"CPP_PREDICTIONS_CSV = CPP_OUTPUT_ROOT / \\\"reports\\\" / \\\"predictions.csv\\\"\\n\",\n",
    "        \"CPP_METRICS_TXT = CPP_OUTPUT_ROOT / \\\"reports\\\" / \\\"metrics.txt\\\"\\n\",\n",
    "        \"\\n\",\n",
    "        \"# Notebook display preferences\\n\",\n",
    "        \"pd.set_option(\\\"display.max_columns\\\", 120)\\n\",\n",
    "        \"pd.set_option(\\\"display.width\\\", 180)\\n\",\n",
    "        \"\\n\",\n",
    "        \"print(\\\"PROJECT_ROOT:\\\", PROJECT_ROOT)\\n\",\n",
    "        \"print(\\\"RAW_DATA_CSV:\\\", RAW_DATA_CSV)\\n\",\n",
    "        \"print(\\\"CPP_OUTPUT_ROOT:\\\", CPP_OUTPUT_ROOT)\\n\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"markdown\",\n",
    "      \"metadata\": {},\n",
    "      \"source\": [\n",
    "        \"## 2) Helper Functions\\n\",\n",
    "        \"\\n\",\n",
    "        \"Utilities for safe loading, quick summaries, plotting, and metric validation.\\n\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"code\",\n",
    "      \"execution_count\": null,\n",
    "      \"metadata\": {},\n",
    "      \"outputs\": [],\n",
    "      \"source\": [\n",
    "        \"def safe_read_csv(path: Path, **kwargs) -> pd.DataFrame | None:\\n\",\n",
    "        \"    \\\"\\\"\\\"Read CSV safely; return None if missing/unreadable.\\\"\\\"\\\"\\n\",\n",
    "        \"    try:\\n\",\n",
    "        \"        if not path.exists():\\n\",\n",
    "        \"            print(f\\\"[WARN] File not found: {path}\\\")\\n\",\n",
    "        \"            return None\\n\",\n",
    "        \"        df = pd.read_csv(path, **kwargs)\\n\",\n",
    "        \"        print(f\\\"[OK] Loaded: {path} | shape={df.shape}\\\")\\n\",\n",
    "        \"        return df\\n\",\n",
    "        \"    except Exception as e:\\n\",\n",
    "        \"        print(f\\\"[ERROR] Failed to read {path}: {e}\\\")\\n\",\n",
    "        \"        return None\\n\",\n",
    "        \"\\n\",\n",
    "        \"\\n\",\n",
    "        \"def summarize_df(df: pd.DataFrame, name: str = \\\"DataFrame\\\", max_rows: int = 5) -> None:\\n\",\n",
    "        \"    if df is None:\\n\",\n",
    "        \"        print(f\\\"[WARN] {name}: None\\\")\\n\",\n",
    "        \"        return\\n\",\n",
    "        \"    print(f\\\"\\\\n=== {name} Summary ===\\\")\\n\",\n",
    "        \"    print(\\\"Shape:\\\", df.shape)\\n\",\n",
    "        \"    print(\\\"\\\\nDtypes:\\\")\\n\",\n",
    "        \"    print(df.dtypes)\\n\",\n",
    "        \"    print(\\\"\\\\nMissing values (top 20):\\\")\\n\",\n",
    "        \"    mv = df.isna().sum().sort_values(ascending=False)\\n\",\n",
    "        \"    print(mv.head(20))\\n\",\n",
    "        \"    print(\\\"\\\\nHead:\\\")\\n\",\n",
    "        \"    display(df.head(max_rows))\\n\",\n",
    "        \"    \\n\",\n",
    "        \"\\n\",\n",
    "        \"def numeric_profile(df: pd.DataFrame, name: str = \\\"numeric_df\\\") -> pd.DataFrame:\\n\",\n",
    "        \"    if df is None:\\n\",\n",
    "        \"        raise ValueError(f\\\"{name} is None\\\")\\n\",\n",
    "        \"    num = df.select_dtypes(include=[np.number])\\n\",\n",
    "        \"    if num.empty:\\n\",\n",
    "        \"        print(f\\\"[WARN] {name}: no numeric columns\\\")\\n\",\n",
    "        \"        return pd.DataFrame()\\n\",\n",
    "        \"    profile = num.describe(percentiles=[0.05, 0.25, 0.5, 0.75, 0.95]).T\\n\",\n",
    "        \"    profile[\\\"missing\\\"] = num.isna().sum()\\n\",\n",
    "        \"    profile[\\\"missing_pct\\\"] = profile[\\\"missing\\\"] / len(num) * 100.0\\n\",\n",
    "        \"    return profile.sort_values(\\\"missing\\\", ascending=False)\\n\",\n",
    "        \"\\n\",\n",
    "        \"\\n\",\n",
    "        \"def plot_numeric_histograms(df: pd.DataFrame, columns=None, bins: int = 40, max_cols: int = 6):\\n\",\n",
    "        \"    \\\"\\\"\\\"Quick histogram plots for selected numeric columns (single-plot style, one column per figure).\\\"\\\"\\\"\\n\",\n",
    "        \"    if df is None:\\n\",\n",
    "        \"        print(\\\"[WARN] DataFrame is None\\\")\\n\",\n",
    "        \"        return\\n\",\n",
    "        \"    num_cols = df.select_dtypes(include=[np.number]).columns.tolist()\\n\",\n",
    "        \"    if columns is None:\\n\",\n",
    "        \"        columns = num_cols[:max_cols]\\n\",\n",
    "        \"    else:\\n\",\n",
    "        \"        columns = [c for c in columns if c in df.columns]\\n\",\n",
    "        \"    if not columns:\\n\",\n",
    "        \"        print(\\\"[WARN] No numeric columns selected.\\\")\\n\",\n",
    "        \"        return\\n\",\n",
    "        \"\\n\",\n",
    "        \"    for col in columns:\\n\",\n",
    "        \"        plt.figure(figsize=(6, 4))\\n\",\n",
    "        \"        series = df[col].dropna()\\n\",\n",
    "        \"        plt.hist(series, bins=bins)\\n\",\n",
    "        \"        plt.title(f\\\"Histogram: {col}\\\")\\n\",\n",
    "        \"        plt.xlabel(col)\\n\",\n",
    "        \"        plt.ylabel(\\\"Count\\\")\\n\",\n",
    "        \"        plt.tight_layout()\\n\",\n",
    "        \"        plt.show()\\n\",\n",
    "        \"\\n\",\n",
    "        \"\\n\",\n",
    "        \"def plot_scatter_true_vs_pred(df_pred: pd.DataFrame):\\n\",\n",
    "        \"    required = {\\\"y_true\\\", \\\"y_pred\\\"}\\n\",\n",
    "        \"    if df_pred is None or not required.issubset(df_pred.columns):\\n\",\n",
    "        \"        print(\\\"[WARN] predictions DataFrame missing required columns:\\\", required)\\n\",\n",
    "        \"        return\\n\",\n",
    "        \"\\n\",\n",
    "        \"    x = pd.to_numeric(df_pred[\\\"y_true\\\"], errors=\\\"coerce\\\")\\n\",\n",
    "        \"    y = pd.to_numeric(df_pred[\\\"y_pred\\\"], errors=\\\"coerce\\\")\\n\",\n",
    "        \"    mask = x.notna() & y.notna()\\n\",\n",
    "        \"    x = x[mask]\\n\",\n",
    "        \"    y = y[mask]\\n\",\n",
    "        \"    if x.empty:\\n\",\n",
    "        \"        print(\\\"[WARN] No valid numeric y_true/y_pred rows.\\\")\\n\",\n",
    "        \"        return\\n\",\n",
    "        \"\\n\",\n",
    "        \"    plt.figure(figsize=(6, 6))\\n\",\n",
    "        \"    plt.scatter(x, y, alpha=0.8)\\n\",\n",
    "        \"    xy_min = float(min(x.min(), y.min()))\\n\",\n",
    "        \"    xy_max = float(max(x.max(), y.max()))\\n\",\n",
    "        \"    plt.plot([xy_min, xy_max], [xy_min, xy_max])  # y=x reference line\\n\",\n",
    "        \"    plt.xlabel(\\\"y_true\\\")\\n\",\n",
    "        \"    plt.ylabel(\\\"y_pred\\\")\\n\",\n",
    "        \"    plt.title(\\\"Predicted vs True (C++ output)\\\")\\n\",\n",
    "        \"    plt.tight_layout()\\n\",\n",
    "        \"    plt.show()\\n\",\n",
    "        \"\\n\",\n",
    "        \"\\n\",\n",
    "        \"def plot_residuals(df_pred: pd.DataFrame):\\n\",\n",
    "        \"    if df_pred is None:\\n\",\n",
    "        \"        print(\\\"[WARN] predictions DataFrame is None\\\")\\n\",\n",
    "        \"        return\\n\",\n",
    "        \"    if \\\"error\\\" in df_pred.columns:\\n\",\n",
    "        \"        residual = pd.to_numeric(df_pred[\\\"error\\\"], errors=\\\"coerce\\\")\\n\",\n",
    "        \"    elif {\\\"y_true\\\", \\\"y_pred\\\"}.issubset(df_pred.columns):\\n\",\n",
    "        \"        residual = pd.to_numeric(df_pred[\\\"y_pred\\\"], errors=\\\"coerce\\\") - pd.to_numeric(df_pred[\\\"y_true\\\"], errors=\\\"coerce\\\")\\n\",\n",
    "        \"    else:\\n\",\n",
    "        \"        print(\\\"[WARN] predictions DataFrame lacks residual/error columns.\\\")\\n\",\n",
    "        \"        return\\n\",\n",
    "        \"\\n\",\n",
    "        \"    residual = residual.dropna()\\n\",\n",
    "        \"    if residual.empty:\\n\",\n",
    "        \"        print(\\\"[WARN] No numeric residuals found.\\\")\\n\",\n",
    "        \"        return\\n\",\n",
    "        \"\\n\",\n",
    "        \"    plt.figure(figsize=(6, 4))\\n\",\n",
    "        \"    plt.hist(residual, bins=40)\\n\",\n",
    "        \"    plt.xlabel(\\\"Residual (y_pred - y_true)\\\")\\n\",\n",
    "        \"    plt.ylabel(\\\"Count\\\")\\n\",\n",
    "        \"    plt.title(\\\"Residual Distribution (C++ output)\\\")\\n\",\n",
    "        \"    plt.tight_layout()\\n\",\n",
    "        \"    plt.show()\\n\",\n",
    "        \"\\n\",\n",
    "        \"\\n\",\n",
    "        \"def rmse_np(y_true: np.ndarray, y_pred: np.ndarray) -> float:\\n\",\n",
    "        \"    e = y_true - y_pred\\n\",\n",
    "        \"    return float(np.sqrt(np.mean(e * e)))\\n\",\n",
    "        \"\\n\",\n",
    "        \"\\n\",\n",
    "        \"def mae_np(y_true: np.ndarray, y_pred: np.ndarray) -> float:\\n\",\n",
    "        \"    return float(np.mean(np.abs(y_true - y_pred)))\\n\",\n",
    "        \"\\n\",\n",
    "        \"\\n\",\n",
    "        \"def r2_np(y_true: np.ndarray, y_pred: np.ndarray, eps: float = 1e-12) -> float:\\n\",\n",
    "        \"    y_bar = float(np.mean(y_true))\\n\",\n",
    "        \"    ss_res = float(np.sum((y_true - y_pred) ** 2))\\n\",\n",
    "        \"    ss_tot = float(np.sum((y_true - y_bar) ** 2))\\n\",\n",
    "        \"    if ss_tot <= eps:\\n\",\n",
    "        \"        return 0.0  # mirror fallback style from C++ implementation\\n\",\n",
    "        \"    return float(1.0 - ss_res / ss_tot)\\n\",\n",
    "        \"\\n\",\n",
    "        \"\\n\",\n",
    "        \"def mape_np(y_true: np.ndarray, y_pred: np.ndarray, eps: float = 1e-12) -> tuple[float | None, int, int]:\\n\",\n",
    "        \"    denom = np.abs(y_true)\\n\",\n",
    "        \"    usable = denom > eps\\n\",\n",
    "        \"    used_count = int(np.sum(usable))\\n\",\n",
    "        \"    skipped_count = int(np.sum(~usable))\\n\",\n",
    "        \"    if used_count == 0:\\n\",\n",
    "        \"        return None, used_count, skipped_count\\n\",\n",
    "        \"    val = float(np.mean(np.abs((y_true[usable] - y_pred[usable]) / denom[usable])) * 100.0)\\n\",\n",
    "        \"    return val, used_count, skipped_count\\n\",\n",
    "        \"\\n\",\n",
    "        \"\\n\",\n",
    "        \"def recompute_metrics_from_predictions(df_pred: pd.DataFrame) -> dict:\\n\",\n",
    "        \"    required = {\\\"y_true\\\", \\\"y_pred\\\"}\\n\",\n",
    "        \"    if df_pred is None or not required.issubset(df_pred.columns):\\n\",\n",
    "        \"        raise ValueError(\\\"Predictions CSV must contain y_true and y_pred columns\\\")\\n\",\n",
    "        \"\\n\",\n",
    "        \"    y_true = pd.to_numeric(df_pred[\\\"y_true\\\"], errors=\\\"coerce\\\").to_numpy(dtype=float)\\n\",\n",
    "        \"    y_pred = pd.to_numeric(df_pred[\\\"y_pred\\\"], errors=\\\"coerce\\\").to_numpy(dtype=float)\\n\",\n",
    "        \"    mask = np.isfinite(y_true) & np.isfinite(y_pred)\\n\",\n",
    "        \"    y_true = y_true[mask]\\n\",\n",
    "        \"    y_pred = y_pred[mask]\\n\",\n",
    "        \"    if y_true.size == 0:\\n\",\n",
    "        \"        raise ValueError(\\\"No valid numeric rows in predictions CSV\\\")\\n\",\n",
    "        \"\\n\",\n",
    "        \"    mape_val, mape_used, mape_skipped = mape_np(y_true, y_pred)\\n\",\n",
    "        \"    return {\\n\",\n",
    "        \"        \\\"n\\\": int(y_true.size),\\n\",\n",
    "        \"        \\\"RMSE\\\": rmse_np(y_true, y_pred),\\n\",\n",
    "        \"        \\\"MAE\\\": mae_np(y_true, y_pred),\\n\",\n",
    "        \"        \\\"R2\\\": r2_np(y_true, y_pred),\\n\",\n",
    "        \"        \\\"MAPE\\\": mape_val,\\n\",\n",
    "        \"        \\\"MAPE_used\\\": mape_used,\\n\",\n",
    "        \"        \\\"MAPE_skipped\\\": mape_skipped,\\n\",\n",
    "        \"    }\\n\",\n",
    "        \"\\n\",\n",
    "        \"\\n\",\n",
    "        \"def parse_cpp_metrics_txt(path: Path) -> dict:\\n\",\n",
    "        \"    \\\"\\\"\\\"\\n\",\n",
    "        \"    Parse the C++ metrics report text (metrics.txt).\\n\",\n",
    "        \"    Looks for lines like:\\n\",\n",
    "        \"      [Test Metrics]\\n\",\n",
    "        \"      n=..., RMSE=..., MAE=..., R2=..., MAPE=...%\\n\",\n",
    "        \"    \\\"\\\"\\\"\\n\",\n",
    "        \"    if not path.exists():\\n\",\n",
    "        \"        print(f\\\"[WARN] Metrics report not found: {path}\\\")\\n\",\n",
    "        \"        return {}\\n\",\n",
    "        \"\\n\",\n",
    "        \"    text = path.read_text(encoding=\\\"utf-8\\\", errors=\\\"replace\\\")\\n\",\n",
    "        \"    # Capture the metrics line after [Test Metrics]\\n\",\n",
    "        \"    m_section = re.search(r\\\"\\\\[Test Metrics\\\\]\\\\s*(.+)\\\", text)\\n\",\n",
    "        \"    line = m_section.group(1).strip() if m_section else \\\"\\\"\\n\",\n",
    "        \"\\n\",\n",
    "        \"    parsed = {}\\n\",\n",
    "        \"    if line:\\n\",\n",
    "        \"        # Flexible parse: key=value pairs separated by commas\\n\",\n",
    "        \"        for part in [p.strip() for p in line.split(\\\",\\\")]:\\n\",\n",
    "        \"            if \\\"=\\\" not in part:\\n\",\n",
    "        \"                continue\\n\",\n",
    "        \"            k, v = part.split(\\\"=\\\", 1)\\n\",\n",
    "        \"            k = k.strip()\\n\",\n",
    "        \"            v = v.strip()\\n\",\n",
    "        \"\\n\",\n",
    "        \"            # normalize MAPE like \\\"12.34% (used=..., skipped=...)\\\"\\n\",\n",
    "        \"            if k.upper() == \\\"MAPE\\\":\\n\",\n",
    "        \"                # numeric prefix before %\\n\",\n",
    "        \"                m_num = re.match(r\\\"([-+]?\\\\d*\\\\.?\\\\d+(?:[eE][-+]?\\\\d+)?)%\\\", v)\\n\",\n",
    "        \"                if m_num:\\n\",\n",
    "        \"                    parsed[\\\"MAPE\\\"] = float(m_num.group(1))\\n\",\n",
    "        \"                else:\\n\",\n",
    "        \"                    parsed[\\\"MAPE\\\"] = None\\n\",\n",
    "        \"                m_used = re.search(r\\\"used=(\\\\d+)\\\", v)\\n\",\n",
    "        \"                m_skipped = re.search(r\\\"skipped=(\\\\d+)\\\", v)\\n\",\n",
    "        \"                if m_used:\\n\",\n",
    "        \"                    parsed[\\\"MAPE_used\\\"] = int(m_used.group(1))\\n\",\n",
    "        \"                if m_skipped:\\n\",\n",
    "        \"                    parsed[\\\"MAPE_skipped\\\"] = int(m_skipped.group(1))\\n\",\n",
    "        \"                continue\\n\",\n",
    "        \"\\n\",\n",
    "        \"            # parse plain float/int for other metrics\\n\",\n",
    "        \"            try:\\n\",\n",
    "        \"                if k == \\\"n\\\":\\n\",\n",
    "        \"                    parsed[k] = int(float(v))\\n\",\n",
    "        \"                else:\\n\",\n",
    "        \"                    parsed[k] = float(v.split()[0])\\n\",\n",
    "        \"            except Exception:\\n\",\n",
    "        \"                parsed[k] = v\\n\",\n",
    "        \"\\n\",\n",
    "        \"    return parsed\\n\",\n",
    "        \"\\n\",\n",
    "        \"\\n\",\n",
    "        \"def compare_metrics(cpp_metrics: dict, py_metrics: dict, tol: float = 1e-6) -> pd.DataFrame:\\n\",\n",
    "        \"    keys = [\\\"n\\\", \\\"RMSE\\\", \\\"MAE\\\", \\\"R2\\\", \\\"MAPE\\\", \\\"MAPE_used\\\", \\\"MAPE_skipped\\\"]\\n\",\n",
    "        \"    rows = []\\n\",\n",
    "        \"    for k in keys:\\n\",\n",
    "        \"        cv = cpp_metrics.get(k, None)\\n\",\n",
    "        \"        pv = py_metrics.get(k, None)\\n\",\n",
    "        \"        if isinstance(cv, (int, float)) and isinstance(pv, (int, float)):\\n\",\n",
    "        \"            diff = float(abs(float(cv) - float(pv)))\\n\",\n",
    "        \"            match = diff <= tol\\n\",\n",
    "        \"        else:\\n\",\n",
    "        \"            diff = None if (cv is None and pv is None) else np.nan\\n\",\n",
    "        \"            match = (cv == pv)\\n\",\n",
    "        \"        rows.append({\\\"metric\\\": k, \\\"cpp\\\": cv, \\\"python_recomputed\\\": pv, \\\"abs_diff\\\": diff, \\\"match\\\": match})\\n\",\n",
    "        \"    return pd.DataFrame(rows)\\n\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"markdown\",\n",
    "      \"metadata\": {},\n",
    "      \"source\": [\n",
    "        \"## 3) Inspect Raw Input Data (optional)\\n\",\n",
    "        \"\\n\",\n",
    "        \"Use this to understand the incoming CSV before/while building the C++ pipeline.  \\n\",\n",
    "        \"This notebook should help you inspect data quality â€” not replace preprocessing logic.\\n\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"code\",\n",
    "      \"execution_count\": null,\n",
    "      \"metadata\": {},\n",
    "      \"outputs\": [],\n",
    "      \"source\": [\n",
    "        \"raw_df = safe_read_csv(RAW_DATA_CSV)\\n\",\n",
    "        \"if raw_df is not None:\\n\",\n",
    "        \"    summarize_df(raw_df, \\\"Raw Input CSV\\\")\\n\",\n",
    "        \"    raw_profile = numeric_profile(raw_df, \\\"raw_df\\\")\\n\",\n",
    "        \"    if not raw_profile.empty:\\n\",\n",
    "        \"        display(raw_profile.head(20))\\n\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"markdown\",\n",
    "      \"metadata\": {},\n",
    "      \"source\": [\n",
    "        \"## 4) Inspect C++ Preprocessed Output\\n\",\n",
    "        \"\\n\",\n",
    "        \"Validate what your C++ preprocessing wrote to `output/data/processed/cleaned.csv`.\\n\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"code\",\n",
    "      \"execution_count\": null,\n",
    "      \"metadata\": {},\n",
    "      \"outputs\": [],\n",
    "      \"source\": [\n",
    "        \"clean_df = safe_read_csv(CPP_PROCESSED_CSV)\\n\",\n",
    "        \"if clean_df is not None:\\n\",\n",
    "        \"    summarize_df(clean_df, \\\"C++ cleaned.csv\\\")\\n\",\n",
    "        \"    clean_profile = numeric_profile(clean_df, \\\"clean_df\\\")\\n\",\n",
    "        \"    if not clean_profile.empty:\\n\",\n",
    "        \"        display(clean_profile.head(20))\\n\",\n",
    "        \"        # Quick visual inspection of a few numeric columns\\n\",\n",
    "        \"        cols = clean_df.select_dtypes(include=[np.number]).columns.tolist()\\n\",\n",
    "        \"        plot_numeric_histograms(clean_df, columns=cols[:6], bins=40)\\n\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"markdown\",\n",
    "      \"metadata\": {},\n",
    "      \"source\": [\n",
    "        \"## 5) Inspect C++ Feature Engineering Outputs\\n\",\n",
    "        \"\\n\",\n",
    "        \"Useful for checking feature counts, constant columns, scaling ranges, and basic distributions.\\n\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"code\",\n",
    "      \"execution_count\": null,\n",
    "      \"metadata\": {},\n",
    "      \"outputs\": [],\n",
    "      \"source\": [\n",
    "        \"features_all_df = safe_read_csv(CPP_FEATURES_ALL_CSV)\\n\",\n",
    "        \"train_scaled_df = safe_read_csv(CPP_TRAIN_SCALED_CSV)\\n\",\n",
    "        \"test_scaled_df = safe_read_csv(CPP_TEST_SCALED_CSV)\\n\",\n",
    "        \"\\n\",\n",
    "        \"if features_all_df is not None:\\n\",\n",
    "        \"    summarize_df(features_all_df, \\\"C++ engineered_all_unscaled.csv\\\", max_rows=3)\\n\",\n",
    "        \"\\n\",\n",
    "        \"if train_scaled_df is not None:\\n\",\n",
    "        \"    summarize_df(train_scaled_df, \\\"C++ train_scaled.csv\\\", max_rows=3)\\n\",\n",
    "        \"\\n\",\n",
    "        \"if test_scaled_df is not None:\\n\",\n",
    "        \"    summarize_df(test_scaled_df, \\\"C++ test_scaled.csv\\\", max_rows=3)\\n\",\n",
    "        \"\\n\",\n",
    "        \"# Check for NaN/Inf in scaled outputs (important sanity check)\\n\",\n",
    "        \"for name, df in [(\\\"train_scaled\\\", train_scaled_df), (\\\"test_scaled\\\", test_scaled_df)]:\\n\",\n",
    "        \"    if df is None:\\n\",\n",
    "        \"        continue\\n\",\n",
    "        \"    num = df.select_dtypes(include=[np.number])\\n\",\n",
    "        \"    if num.empty:\\n\",\n",
    "        \"        print(f\\\"[WARN] {name}: no numeric columns found.\\\")\\n\",\n",
    "        \"        continue\\n\",\n",
    "        \"    finite_mask = np.isfinite(num.to_numpy(dtype=float))\\n\",\n",
    "        \"    print(f\\\"[CHECK] {name}: all finite =\\\", bool(finite_mask.all()))\\n\",\n",
    "        \"    print(f\\\"[CHECK] {name}: total NaN =\\\", int(np.isnan(num.to_numpy(dtype=float)).sum()))\\n\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"markdown\",\n",
    "      \"metadata\": {},\n",
    "      \"source\": [\n",
    "        \"## 6) Validate C++ Predictions and Metrics (Main Notebook Purpose)\\n\",\n",
    "        \"\\n\",\n",
    "        \"This is the key notebook workflow for your C++ goal:\\n\",\n",
    "        \"- read `output/reports/predictions.csv`\\n\",\n",
    "        \"- recompute metrics in Python\\n\",\n",
    "        \"- compare against C++ `metrics.txt`\\n\",\n",
    "        \"\\n\",\n",
    "        \"If these match (within tolerance), your C++ evaluation pipeline is likely correct.\\n\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"code\",\n",
    "      \"execution_count\": null,\n",
    "      \"metadata\": {},\n",
    "      \"outputs\": [],\n",
    "      \"source\": [\n",
    "        \"pred_df = safe_read_csv(CPP_PREDICTIONS_CSV)\\n\",\n",
    "        \"cpp_metrics = parse_cpp_metrics_txt(CPP_METRICS_TXT)\\n\",\n",
    "        \"\\n\",\n",
    "        \"if pred_df is not None:\\n\",\n",
    "        \"    summarize_df(pred_df, \\\"C++ predictions.csv\\\")\\n\",\n",
    "        \"\\n\",\n",
    "        \"    py_metrics = recompute_metrics_from_predictions(pred_df)\\n\",\n",
    "        \"    print(\\\"\\\\nPython recomputed metrics:\\\")\\n\",\n",
    "        \"    print(json.dumps(py_metrics, indent=2, default=str))\\n\",\n",
    "        \"\\n\",\n",
    "        \"    print(\\\"\\\\nParsed C++ metrics.txt (test metrics):\\\")\\n\",\n",
    "        \"    print(json.dumps(cpp_metrics, indent=2, default=str))\\n\",\n",
    "        \"\\n\",\n",
    "        \"    cmp_df = compare_metrics(cpp_metrics, py_metrics, tol=1e-6)\\n\",\n",
    "        \"    display(cmp_df)\\n\",\n",
    "        \"\\n\",\n",
    "        \"    if not cmp_df.empty and \\\"match\\\" in cmp_df.columns:\\n\",\n",
    "        \"        mismatches = cmp_df[cmp_df[\\\"match\\\"] == False]\\n\",\n",
    "        \"        if len(mismatches) == 0:\\n\",\n",
    "        \"            print(\\\"[OK] C++ metrics and Python recomputed metrics match within tolerance.\\\")\\n\",\n",
    "        \"        else:\\n\",\n",
    "        \"            print(\\\"[WARN] Metric mismatches found. Inspect rows above.\\\")\\n\",\n",
    "        \"else:\\n\",\n",
    "        \"    print(\\\"[INFO] Run the C++ pipeline first to generate predictions.csv and metrics.txt.\\\")\\n\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"markdown\",\n",
    "      \"metadata\": {},\n",
    "      \"source\": [\n",
    "        \"## 7) Plot Model Behavior from C++ Outputs\\n\",\n",
    "        \"\\n\",\n",
    "        \"Simple visual diagnostics (scatter + residuals) to support quick analysis.\\n\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"code\",\n",
    "      \"execution_count\": null,\n",
    "      \"metadata\": {},\n",
    "      \"outputs\": [],\n",
    "      \"source\": [\n",
    "        \"if pred_df is not None:\\n\",\n",
    "        \"    plot_scatter_true_vs_pred(pred_df)\\n\",\n",
    "        \"    plot_residuals(pred_df)\\n\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"markdown\",\n",
    "      \"metadata\": {},\n",
    "      \"source\": [\n",
    "        \"## 8) Quick Experiments (Optional, Notebook-only)\\n\",\n",
    "        \"\\n\",\n",
    "        \"This section is intentionally small and optional.  \\n\",\n",
    "        \"It can help you **understand the data** or sanity-check trends, but it must **not replace** the C++ pipeline.\\n\",\n",
    "        \"\\n\",\n",
    "        \"Example below: correlation scan with target (if the target exists in `cleaned.csv`).\\n\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"code\",\n",
    "      \"execution_count\": null,\n",
    "      \"metadata\": {},\n",
    "      \"outputs\": [],\n",
    "      \"source\": [\n",
    "        \"if clean_df is not None:\\n\",\n",
    "        \"    numeric_cols = clean_df.select_dtypes(include=[np.number]).columns.tolist()\\n\",\n",
    "        \"    # Try to infer target column from predictions/metrics or report; fallback to last numeric column\\n\",\n",
    "        \"    guessed_target = None\\n\",\n",
    "        \"    if \\\"y_true\\\" in (pred_df.columns if pred_df is not None else []):\\n\",\n",
    "        \"        # predictions.csv doesn't include target name; just a reminder\\n\",\n",
    "        \"        pass\\n\",\n",
    "        \"\\n\",\n",
    "        \"    # If your C++ cleaned.csv includes target column, set it manually here for quick experiments:\\n\",\n",
    "        \"    # guessed_target = \\\"adsorption_capacity\\\"\\n\",\n",
    "        \"    # guessed_target = \\\"surface_area\\\"\\n\",\n",
    "        \"\\n\",\n",
    "        \"    if guessed_target is None:\\n\",\n",
    "        \"        print(\\\"[INFO] Set `guessed_target` manually to compute correlations with target.\\\")\\n\",\n",
    "        \"    elif guessed_target not in clean_df.columns:\\n\",\n",
    "        \"        print(f\\\"[WARN] guessed_target '{guessed_target}' not found in clean_df\\\")\\n\",\n",
    "        \"    else:\\n\",\n",
    "        \"        corr = clean_df[numeric_cols].corr(numeric_only=True)[guessed_target].sort_values(key=np.abs, ascending=False)\\n\",\n",
    "        \"        display(corr.to_frame(\\\"corr_with_target\\\").head(20))\\n\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"cell_type\": \"markdown\",\n",
    "      \"metadata\": {},\n",
    "      \"source\": [\n",
    "        \"## 9) C++-First Workflow Checklist\\n\",\n",
    "        \"\\n\",\n",
    "        \"Use this notebook as a **validation companion** after running the C++ executable.\\n\",\n",
    "        \"\\n\",\n",
    "        \"### Recommended loop\\n\",\n",
    "        \"1. Run C++ pipeline (`src/main.cpp`) on a dataset.\\n\",\n",
    "        \"2. Confirm outputs exist:\\n\",\n",
    "        \"   - `output/data/processed/cleaned.csv`\\n\",\n",
    "        \"   - `output/data/features/*.csv`\\n\",\n",
    "        \"   - `output/reports/predictions.csv`\\n\",\n",
    "        \"   - `output/reports/metrics.txt`\\n\",\n",
    "        \"3. Open this notebook and:\\n\",\n",
    "        \"   - inspect data quality\\n\",\n",
    "        \"   - inspect feature outputs\\n\",\n",
    "        \"   - recompute metrics from `predictions.csv`\\n\",\n",
    "        \"   - compare against C++ report\\n\",\n",
    "        \"4. Fix C++ code if anything looks wrong.\\n\",\n",
    "        \"5. Re-run C++ pipeline.\\n\",\n",
    "        \"\\n\",\n",
    "        \"### Anti-pattern to avoid\\n\",\n",
    "        \"- Adding full training logic in Python and treating the notebook as the real pipeline.\\n\",\n",
    "        \"\\n\",\n",
    "        \"Your goal is **C++**, so this notebook stays for analysis and validation only.\\n\"\n",
    "      ]\n",
    "    }\n",
    "  ],\n",
    "  \"metadata\": {\n",
    "    \"kernelspec\": {\n",
    "      \"display_name\": \"Python 3\",\n",
    "      \"language\": \"python\",\n",
    "      \"name\": \"python3\"\n",
    "    },\n",
    "    \"language_info\": {\n",
    "      \"name\": \"python\",\n",
    "      \"version\": \"3.11\"\n",
    "    }\n",
    "  },\n",
    "  \"nbformat\": 4,\n",
    "  \"nbformat_minor\": 5\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
